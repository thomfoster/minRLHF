{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import minRLHF\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM, \n",
    "    AutoModelForTokenClassification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/text_classification.py:89: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from minRLHF.environment import Environment\n",
    "import random\n",
    "from transformers.pipelines import pipeline\n",
    "\n",
    "reward_model = pipeline(\n",
    "    \"text-classification\",\n",
    "    model='bhadresh-savani/distilbert-base-uncased-emotion', \n",
    "    return_all_scores=True\n",
    ")\n",
    "\n",
    "class MyEnv(Environment):\n",
    "    def get_input_prompt(self) -> str:\n",
    "        return random.choice([\n",
    "            'I went for a walk one day and',\n",
    "            'A long time ago, in a galaxy far far away',\n",
    "            'Oops! I'\n",
    "        ])\n",
    "        \n",
    "    def score_generation(self, text: str) -> float:\n",
    "        sentiment_scores = reward_model(text)[0]\n",
    "        sentiment_scores = {d['label']: d['score'] for d in sentiment_scores}\n",
    "        return sentiment_scores['joy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForTokenClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'classifier.bias', 'h.4.attn.masked_bias', 'h.9.attn.masked_bias', 'h.8.attn.masked_bias', 'classifier.weight', 'h.2.attn.masked_bias', 'h.11.attn.masked_bias', 'h.3.attn.masked_bias', 'h.10.attn.masked_bias', 'h.7.attn.masked_bias', 'h.5.attn.masked_bias', 'h.1.attn.masked_bias', 'h.6.attn.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = 'left'\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained('gpt2').to('cuda')\n",
    "reference = AutoModelForCausalLM.from_pretrained('gpt2').to('cuda')\n",
    "critic = AutoModelForTokenClassification.from_pretrained('gpt2', num_labels=1).to('cuda')\n",
    "\n",
    "# Instantiate envrionment\n",
    "env = MyEnv(tokenizer, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minRLHF.ppo_trainer import PPOTrainer\n",
    "\n",
    "# Create PPO trainer\n",
    "ppo_trainer = PPOTrainer(\n",
    "    actor_model=model,\n",
    "    critic_model=critic,\n",
    "    reference_model=reference,\n",
    "    env=env,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch 0.\n",
      "reward_mean: 0.506142258644104 (0.506142258644104 average)\n",
      "reward_std: 0.4182848632335663 (0.4182848632335663 average)\n",
      "augmented_reward: -0.011102182790637016 (-0.011102182790637016 average)\n",
      "completion_length_mean: 89.0 (89.0 average)\n",
      "completion_length_std: 0.0 (0.0 average)\n",
      "kld_t-1: -0.626872181892395 (-0.626872181892395 average)\n",
      "kld_0: -1.366380214691162 (-1.366380214691162 average)\n",
      "entropy: 1.9532020092010498 (1.9532020092010498 average)\n",
      "mae: 1.321537733078003 (1.321537733078003 average)\n",
      "\n",
      "Completed epoch 1.\n",
      "reward_mean: 0.5330030918121338 (0.5064108669757843 average)\n",
      "reward_std: 0.4213164448738098 (0.41831517904996873 average)\n",
      "augmented_reward: -0.886354386806488 (-0.019854704830795537 average)\n",
      "completion_length_mean: 89.0 (89.0 average)\n",
      "completion_length_std: 0.0 (0.0 average)\n",
      "kld_t-1: -0.07289758324623108 (-0.6213324359059335 average)\n",
      "kld_0: -2.145955801010132 (-1.374175970554352 average)\n",
      "entropy: 1.6252460479736328 (1.9499224495887755 average)\n",
      "mae: 1.1221396923065186 (1.3195437526702882 average)\n",
      "\n",
      "Completed epoch 2.\n",
      "reward_mean: 0.4972434639930725 (0.5063191929459572 average)\n",
      "reward_std: 0.4715230464935303 (0.41884725772440434 average)\n",
      "augmented_reward: -0.7326575517654419 (-0.026982733300142007 average)\n",
      "completion_length_mean: 89.0 (89.0 average)\n",
      "completion_length_std: 0.0 (0.0 average)\n",
      "kld_t-1: -0.05976397171616554 (-0.6157167512640358 average)\n",
      "kld_0: -1.8912017345428467 (-1.3793462281942368 average)\n",
      "entropy: 1.667578935623169 (1.9470990144491194 average)\n",
      "mae: 1.0017826557159424 (1.3163661417007446 average)\n",
      "\n",
      "Completed epoch 3.\n",
      "reward_mean: 0.3623250424861908 (0.5048792514413595 average)\n",
      "reward_std: 0.44979503750801086 (0.4191567355222404 average)\n",
      "augmented_reward: -1.0206496715545654 (-0.036919402682686245 average)\n",
      "completion_length_mean: 89.0 (89.0 average)\n",
      "completion_length_std: 0.0 (0.0 average)\n",
      "kld_t-1: -0.01128578744828701 (-0.6096724416258783 average)\n",
      "kld_0: -1.8720991611480713 (-1.3842737575237751 average)\n",
      "entropy: 1.6569881439208984 (1.9441979057438372 average)\n",
      "mae: 0.9872707724571228 (1.3130751880083085 average)\n",
      "\n",
      "Completed epoch 4.\n",
      "reward_mean: 0.4753091335296631 (0.5045835502622426 average)\n",
      "reward_std: 0.4423638582229614 (0.4193888067492476 average)\n",
      "augmented_reward: -1.0262982845306396 (-0.046813191501165786 average)\n",
      "completion_length_mean: 89.0 (89.0 average)\n",
      "completion_length_std: 0.0 (0.0 average)\n",
      "kld_t-1: -0.05332040414214134 (-0.604108921251041 average)\n",
      "kld_0: -1.8855726718902588 (-1.3892867466674401 average)\n",
      "entropy: 1.6962499618530273 (1.941718426304929 average)\n",
      "mae: 1.4117873907089233 (1.3140623100353146 average)\n",
      "\n",
      "Completed epoch 5.\n",
      "reward_mean: 0.4136417508125305 (0.5036741322677454 average)\n",
      "reward_std: 0.4677377939224243 (0.41987229662097936 average)\n",
      "augmented_reward: -0.8578307032585144 (-0.054923366618739276 average)\n",
      "completion_length_mean: 89.0 (89.0 average)\n",
      "completion_length_std: 0.0 (0.0 average)\n",
      "kld_t-1: -0.07302269339561462 (-0.5987980589724867 average)\n",
      "kld_0: -1.7300429344177246 (-1.3926943085449428 average)\n",
      "entropy: 1.6233986616134644 (1.9385352286580144 average)\n",
      "mae: 1.0669755935668945 (1.3115914428706303 average)\n",
      "\n",
      "Completed epoch 6.\n",
      "reward_mean: 0.46189945936203003 (0.5032563855386882 average)\n",
      "reward_std: 0.4566292464733124 (0.42023986611950265 average)\n",
      "augmented_reward: -0.8499272465705872 (-0.06287340541825776 average)\n",
      "completion_length_mean: 89.0 (89.0 average)\n",
      "completion_length_std: 0.0 (0.0 average)\n",
      "kld_t-1: -0.0740397498011589 (-0.5935504758807735 average)\n",
      "kld_0: -1.8379614353179932 (-1.3971469798126734 average)\n",
      "entropy: 1.6020898818969727 (1.9351707751904041 average)\n",
      "mae: 0.9935896992683411 (1.3084114254346075 average)\n",
      "\n",
      "Completed epoch 7.\n",
      "reward_mean: 0.2651037871837616 (0.500874859555139 average)\n",
      "reward_std: 0.3815126121044159 (0.4198525935793518 average)\n",
      "augmented_reward: -1.2008552551269531 (-0.07425322391534472 average)\n",
      "completion_length_mean: 89.0 (89.0 average)\n",
      "completion_length_std: 0.0 (0.0 average)\n",
      "kld_t-1: -0.03824407607316971 (-0.5879974118826974 average)\n",
      "kld_0: -1.8142415285110474 (-1.401317925299657 average)\n",
      "entropy: 1.5292216539382935 (1.931111283977883 average)\n",
      "mae: 0.8663318157196045 (1.3039906293374575 average)\n",
      "\n",
      "Completed epoch 8.\n",
      "reward_mean: 0.10282453149557114 (0.4968943562745433 average)\n",
      "reward_std: 0.17535889148712158 (0.4174076565584295 average)\n",
      "augmented_reward: -1.4904637336730957 (-0.08841532901292225 average)\n",
      "completion_length_mean: 89.0 (89.0 average)\n",
      "completion_length_std: 0.0 (0.0 average)\n",
      "kld_t-1: -0.006140017881989479 (-0.5821788379426903 average)\n",
      "kld_0: -1.9884119033813477 (-1.407188865080474 average)\n",
      "entropy: 1.4984796047210693 (1.9267849671853148 average)\n",
      "mae: 0.9126326441764832 (1.3000770494858478 average)\n",
      "\n",
      "Completed epoch 9.\n",
      "reward_mean: 0.1921795904636383 (0.4938472086164342 average)\n",
      "reward_std: 0.3487545847892761 (0.41672112584073795 average)\n",
      "augmented_reward: -0.9222676753997803 (-0.09675385247679083 average)\n",
      "completion_length_mean: 89.0 (89.0 average)\n",
      "completion_length_std: 0.0 (0.0 average)\n",
      "kld_t-1: -0.03228834643959999 (-0.5766799330276594 average)\n",
      "kld_0: -1.192828893661499 (-1.4050452653662844 average)\n",
      "entropy: 1.6966698169708252 (1.9244838156831698 average)\n",
      "mae: 1.0994188785552979 (1.2980704677765422 average)\n",
      "\n",
      "Completed epoch 10.\n",
      "reward_mean: 0.2614324986934662 (0.49152306151720454 average)\n",
      "reward_std: 0.38368725776672363 (0.4163907871599978 average)\n",
      "augmented_reward: -1.4598524570465088 (-0.11038483852248801 average)\n",
      "completion_length_mean: 89.0 (89.0 average)\n",
      "completion_length_std: 0.0 (0.0 average)\n",
      "kld_t-1: -0.0908370390534401 (-0.5718215040879172 average)\n",
      "kld_0: -2.2556684017181396 (-1.4135514967298028 average)\n",
      "entropy: 1.3872929811477661 (1.9191119073378158 average)\n",
      "mae: 0.6649842858314514 (1.2917396059570914 average)\n",
      "\n",
      "Completed epoch 11.\n",
      "reward_mean: 0.22392797470092773 (0.48884711064904174 average)\n",
      "reward_std: 0.35489732027053833 (0.41577585249110316 average)\n",
      "augmented_reward: -1.2672269344329834 (-0.12195325948159297 average)\n",
      "completion_length_mean: 89.0 (89.0 average)\n",
      "completion_length_std: 0.0 (0.0 average)\n",
      "kld_t-1: -0.1117720678448677 (-0.5672210097254867 average)\n",
      "kld_0: -1.938556432723999 (-1.4188015460897447 average)\n",
      "entropy: 1.4245120286941528 (1.9141659085513791 average)\n",
      "mae: 0.8440768718719482 (1.28726297861624 average)\n",
      "\n",
      "Completed epoch 12.\n",
      "reward_mean: 0.256730318069458 (0.4865259427232459 average)\n",
      "reward_std: 0.3689914047718048 (0.4153080080139102 average)\n",
      "augmented_reward: -1.3897950649261475 (-0.13463167753603852 average)\n",
      "completion_length_mean: 89.0 (89.0 average)\n",
      "completion_length_std: 0.0 (0.0 average)\n",
      "kld_t-1: -0.0671382024884224 (-0.5622201816531162 average)\n",
      "kld_0: -1.9250394105911255 (-1.4238639247347584 average)\n",
      "entropy: 1.4285091161727905 (1.9093093406275932 average)\n",
      "mae: 0.8527918457984924 (1.2829182672880626 average)\n",
      "\n",
      "Completed epoch 13.\n",
      "reward_mean: 0.20458929240703583 (0.4837065762200838 average)\n",
      "reward_std: 0.3929954469203949 (0.4150848824029751 average)\n",
      "augmented_reward: -1.9795948266983032 (-0.1530813090276612 average)\n",
      "completion_length_mean: 89.0 (89.0 average)\n",
      "completion_length_std: 0.0 (0.0 average)\n",
      "kld_t-1: 0.022725271061062813 (-0.5563707271259744 average)\n",
      "kld_0: -2.5239832401275635 (-1.4348651178886864 average)\n",
      "entropy: 1.3450995683670044 (1.9036672429049875 average)\n",
      "mae: 0.8366467952728271 (1.2784555525679102 average)\n",
      "\n",
      "Completed epoch 14.\n",
      "reward_mean: 0.16936829686164856 (0.48056319342649945 average)\n",
      "reward_std: 0.2570666968822479 (0.4135047005477678 average)\n",
      "augmented_reward: -1.6562507152557373 (-0.16811300308994198 average)\n",
      "completion_length_mean: 89.0 (89.0 average)\n",
      "completion_length_std: 0.0 (0.0 average)\n",
      "kld_t-1: -0.11657591909170151 (-0.5519727790456316 average)\n",
      "kld_0: -2.092360019683838 (-1.441440066906638 average)\n",
      "entropy: 1.4305413961410522 (1.8989359844373481 average)\n",
      "mae: 0.8167542815208435 (1.2738385398574394 average)\n",
      "\n",
      "Completed epoch 15.\n",
      "reward_mean: 0.3062594532966614 (0.47882015602520106 average)\n",
      "reward_std: 0.39940160512924194 (0.4133636695935825 average)\n",
      "augmented_reward: -2.11793851852417 (-0.18761125824428426 average)\n",
      "completion_length_mean: 89.0 (89.0 average)\n",
      "completion_length_std: 0.0 (0.0 average)\n",
      "kld_t-1: -0.012984936125576496 (-0.5465829006164311 average)\n",
      "kld_0: -2.705125331878662 (-1.4540769195563583 average)\n",
      "entropy: 1.3552888631820679 (1.8934995132247951 average)\n",
      "mae: 0.7555344700813293 (1.2686554991596783 average)\n",
      "\n",
      "Completed epoch 16.\n",
      "reward_mean: 0.3040759563446045 (0.47707271402839513 average)\n",
      "reward_std: 0.4222399592399597 (0.4134524324900463 average)\n",
      "augmented_reward: -1.4111416339874268 (-0.1998465620017157 average)\n",
      "completion_length_mean: 89.0 (89.0 average)\n",
      "completion_length_std: 0.0 (0.0 average)\n",
      "kld_t-1: -0.01636502332985401 (-0.5412807218435653 average)\n",
      "kld_0: -1.542891263961792 (-1.4549650630004125 average)\n",
      "entropy: 1.495958685874939 (1.8895241049512965 average)\n",
      "mae: 0.7601693868637085 (1.2635706380367187 average)\n",
      "\n",
      "Completed epoch 17.\n",
      "reward_mean: 0.23823949694633484 (0.4746843818575745 average)\n",
      "reward_std: 0.3658836781978607 (0.41297674494712444 average)\n",
      "augmented_reward: -1.1082018613815308 (-0.20893011499551384 average)\n",
      "completion_length_mean: 89.0 (89.0 average)\n",
      "completion_length_std: 0.0 (0.0 average)\n",
      "kld_t-1: -0.08072005212306976 (-0.5366751151463605 average)\n",
      "kld_0: -1.3055201768875122 (-1.4534706141392835 average)\n",
      "entropy: 1.5550389289855957 (1.8861792531916395 average)\n",
      "mae: 0.7296127080917358 (1.2582310587372687 average)\n",
      "\n",
      "Completed epoch 18.\n",
      "reward_mean: 0.1896761953830719 (0.47183429999282944 average)\n",
      "reward_std: 0.32549402117729187 (0.4121019177094261 average)\n",
      "augmented_reward: -1.3570340871810913 (-0.2204111547173696 average)\n",
      "completion_length_mean: 89.0 (89.0 average)\n",
      "completion_length_std: 0.0 (0.0 average)\n",
      "kld_t-1: -0.09993087500333786 (-0.5323076727449303 average)\n",
      "kld_0: -1.4385875463485718 (-1.4533217834613765 average)\n",
      "entropy: 1.673931360244751 (1.8840567742621708 average)\n",
      "mae: 0.812685489654541 (1.2537756030464413 average)\n",
      "\n",
      "Early stopping at 1 due to kl of ~ 0.27201366424560547\n",
      "Completed epoch 19.\n",
      "reward_mean: 0.3673930764198303 (0.47078988775709946 average)\n",
      "reward_std: 0.44866830110549927 (0.4124675815433868 average)\n",
      "augmented_reward: -2.5424084663391113 (-0.24363112783358704 average)\n",
      "completion_length_mean: 89.0 (89.0 average)\n",
      "completion_length_std: 0.0 (0.0 average)\n",
      "kld_t-1: 0.27201366424560547 (-0.5242644593750249 average)\n",
      "kld_0: -2.4087460041046143 (-1.4628760256678088 average)\n",
      "entropy: 1.287043809890747 (1.8780866446184565 average)\n",
      "mae: 0.5449948906898499 (1.2466877959228753 average)\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 308.00 MiB (GPU 0; 14.76 GiB total capacity; 13.01 GiB already allocated; 283.75 MiB free; 13.51 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mppo_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/minRLHF/minRLHF/ppo_trainer.py:203\u001b[0m, in \u001b[0;36mPPOTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/minRLHF/ppo_trainer.py?line=200'>201</a>\u001b[0m \u001b[39m# Use the rollouts to optimise the actor\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/minRLHF/ppo_trainer.py?line=201'>202</a>\u001b[0m \u001b[39mfor\u001b[39;00m actor_train_step \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactor_train_iters):\n\u001b[0;32m--> <a href='file:///home/ubuntu/minRLHF/minRLHF/ppo_trainer.py?line=202'>203</a>\u001b[0m     actor_loss, actor_loss_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_actor_loss(buf_data)\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/minRLHF/ppo_trainer.py?line=204'>205</a>\u001b[0m     \u001b[39mif\u001b[39;00m actor_loss_info[\u001b[39m'\u001b[39m\u001b[39mkld_t-1\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m1.5\u001b[39m \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_kl:\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/minRLHF/ppo_trainer.py?line=205'>206</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEarly stopping at \u001b[39m\u001b[39m{\u001b[39;00mactor_train_step\u001b[39m}\u001b[39;00m\u001b[39m due to kl of ~\u001b[39m\u001b[39m'\u001b[39m, actor_loss_info[\u001b[39m'\u001b[39m\u001b[39mkld_t-1\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/minRLHF/minRLHF/ppo_trainer.py:123\u001b[0m, in \u001b[0;36mPPOTrainer.compute_actor_loss\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/minRLHF/ppo_trainer.py?line=120'>121</a>\u001b[0m masked_logprobs_0 \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mpi_0_logprobs\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmasked_select(data[\u001b[39m'\u001b[39m\u001b[39mcompletion_mask\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mbool))\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/minRLHF/ppo_trainer.py?line=121'>122</a>\u001b[0m kld_0 \u001b[39m=\u001b[39m (masked_logprobs \u001b[39m-\u001b[39m masked_logprobs_0)\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mitem()\n\u001b[0;32m--> <a href='file:///home/ubuntu/minRLHF/minRLHF/ppo_trainer.py?line=122'>123</a>\u001b[0m entropy \u001b[39m=\u001b[39m pi\u001b[39m.\u001b[39;49mentropy()\u001b[39m.\u001b[39mmasked_select(data[\u001b[39m'\u001b[39m\u001b[39mcompletion_mask\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mbool))\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/minRLHF/ppo_trainer.py?line=124'>125</a>\u001b[0m \u001b[39mreturn\u001b[39;00m loss, {\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/minRLHF/ppo_trainer.py?line=125'>126</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mkld_t-1\u001b[39m\u001b[39m'\u001b[39m: kld_t,\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/minRLHF/ppo_trainer.py?line=126'>127</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mkld_0\u001b[39m\u001b[39m'\u001b[39m: kld_0,\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/minRLHF/ppo_trainer.py?line=127'>128</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mentropy\u001b[39m\u001b[39m'\u001b[39m: entropy\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/minRLHF/ppo_trainer.py?line=128'>129</a>\u001b[0m }\n",
      "File \u001b[0;32m~/minRLHF/.venv/lib/python3.8/site-packages/torch/distributions/categorical.py:126\u001b[0m, in \u001b[0;36mCategorical.entropy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/distributions/categorical.py?line=123'>124</a>\u001b[0m min_real \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfinfo(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogits\u001b[39m.\u001b[39mdtype)\u001b[39m.\u001b[39mmin\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/distributions/categorical.py?line=124'>125</a>\u001b[0m logits \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mclamp(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogits, \u001b[39mmin\u001b[39m\u001b[39m=\u001b[39mmin_real)\n\u001b[0;32m--> <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/distributions/categorical.py?line=125'>126</a>\u001b[0m p_log_p \u001b[39m=\u001b[39m logits \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprobs\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/distributions/categorical.py?line=126'>127</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39mp_log_p\u001b[39m.\u001b[39msum(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 308.00 MiB (GPU 0; 14.76 GiB total capacity; 13.01 GiB already allocated; 283.75 MiB free; 13.51 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "ppo_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f07e3707340>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xs = list(range(len(ppo_trainer.rolling_rewards)))\n",
    "ys = ppo_trainer.rolling_rewards\n",
    "\n",
    "window_size = 10\n",
    "smoothed_ys = [sum(ys[max(0, idx-window_size):idx])/window_size for idx, _ in enumerate(ys)]\n",
    "\n",
    "plt.scatter(xs, ys, s=1)\n",
    "plt.plot(smoothed_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer('I went for a walk one day and', return_tensors='pt')\n",
    "outputs = reference.generate(inputs.input_ids.to(model.device), max_length=100, do_sample=True)\n",
    "text = tokenizer.batch_decode(outputs)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3f08a5f13ca9247f60687871aeb0db0c250749e5b174701901907dc6c613fa60"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
