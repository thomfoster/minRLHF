{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define our environment by implementing:\n",
    "- `get_input_prompt` which returns a prompt for the model to respond to \n",
    "- and `score_generation` which scores the models completions according to our reward model - in this case a pretrained sentiment analysis model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/text_classification.py:89: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM, \n",
    "    AutoModelForTokenClassification\n",
    ")\n",
    "\n",
    "from minRLHF.environment import Environment\n",
    "import random\n",
    "from transformers.pipelines import pipeline\n",
    "\n",
    "reward_model = pipeline(\n",
    "    \"text-classification\",\n",
    "    model='bhadresh-savani/distilbert-base-uncased-emotion', \n",
    "    return_all_scores=True\n",
    ")\n",
    "\n",
    "class MyEnv(Environment):\n",
    "    def get_input_prompt(self) -> str:\n",
    "        return random.choice([\n",
    "            'I went for a walk one day and',\n",
    "            'A long time ago, in a galaxy far far away',\n",
    "            'Oops! I'\n",
    "        ])\n",
    "        \n",
    "    def score_generation(self, text: str) -> float:\n",
    "        sentiment_scores = reward_model(text)[0]\n",
    "        sentiment_scores = {d['label']: d['score'] for d in sentiment_scores}\n",
    "        return sentiment_scores['joy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We require 3 transformers for PPO\n",
    "1. `model` the language model we'll be optimising\n",
    "2. `reference` a copy of the the language model that doesn't get optimised. PPO will penalise any updates that leave `model` too far away from `reference`.\n",
    "3. `critic` used to decide what spans of the generation contributed to high/low rewards.\n",
    "\n",
    "The env takes a tokenizer, and will handle translation from the model domain and back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForTokenClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.2.attn.masked_bias', 'h.4.attn.masked_bias', 'h.8.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.3.attn.masked_bias', 'classifier.weight', 'classifier.bias', 'h.0.attn.masked_bias', 'h.10.attn.masked_bias', 'h.5.attn.masked_bias', 'h.9.attn.masked_bias', 'h.1.attn.masked_bias', 'h.11.attn.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = 'left'\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained('gpt2').to('cuda')\n",
    "reference = AutoModelForCausalLM.from_pretrained('gpt2').to('cuda')\n",
    "critic = AutoModelForTokenClassification.from_pretrained('gpt2', num_labels=1).to('cuda')\n",
    "\n",
    "# Instantiate envrionment\n",
    "env = MyEnv(tokenizer, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create the PPO Trainer using the default arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minRLHF.ppo_trainer import PPOTrainer\n",
    "\n",
    "# Create PPO trainer\n",
    "ppo_trainer = PPOTrainer(\n",
    "    actor_model=model,\n",
    "    critic_model=critic,\n",
    "    reference_model=reference,\n",
    "    env=env,\n",
    "    log_steps=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch:10 actor iter: 3) Early stopping due to kl of ~ 0.07794960553292185\n",
      "(Epoch:15 actor iter: 1) Early stopping due to kl of ~ 0.11905228346586227\n",
      "Completed epoch 19.\n",
      "reward_mean: 0.4218469914492096\n",
      "reward_std: 0.4336693298464969\n",
      "augmented_reward: -2.0542066301737614\n",
      "completion_length_mean: 87.40486330554812\n",
      "completion_length_std: 8.593270750205308\n",
      "kld_t-1: -0.06936095597179696\n",
      "kld_0: -0.2388941554197446\n",
      "entropy: 2.844676950658347\n",
      "\n",
      "Completed epoch 39.\n",
      "reward_mean: 0.4272964709241289\n",
      "reward_std: 0.4277830696065565\n",
      "augmented_reward: -6.29159349622074\n",
      "completion_length_mean: 87.85746843609479\n",
      "completion_length_std: 7.216559080485291\n",
      "kld_t-1: -0.026202583147122056\n",
      "kld_0: -0.977302173345351\n",
      "entropy: 2.4105152700408707\n",
      "\n",
      "(Epoch: 49) Saved model to actor_49.model\n",
      "Completed epoch 59.\n",
      "reward_mean: 0.4385270238080286\n",
      "reward_std: 0.4255471416972173\n",
      "augmented_reward: -7.281851622218626\n",
      "completion_length_mean: 87.96953933067161\n",
      "completion_length_std: 7.174089840682527\n",
      "kld_t-1: -0.008019383356933196\n",
      "kld_0: -1.2294414386539796\n",
      "entropy: 2.2365034842351466\n",
      "\n",
      "Completed epoch 79.\n",
      "reward_mean: 0.47041921952140436\n",
      "reward_std: 0.42630817592013553\n",
      "augmented_reward: -7.210533134936743\n",
      "completion_length_mean: 87.8906895585262\n",
      "completion_length_std: 7.349587573207868\n",
      "kld_t-1: -0.002187889252352839\n",
      "kld_0: -1.2844661231458168\n",
      "entropy: 2.1569253003777717\n",
      "\n",
      "Completed epoch 99.\n",
      "reward_mean: 0.4995640719057009\n",
      "reward_std: 0.42452169047661\n",
      "augmented_reward: -6.5122783799305335\n",
      "completion_length_mean: 87.98983364159258\n",
      "completion_length_std: 6.845273875111869\n",
      "kld_t-1: -0.0014548635714582226\n",
      "kld_0: -1.241983350642621\n",
      "entropy: 2.1253495563535827\n",
      "\n",
      "(Epoch: 99) Saved model to actor_99.model\n",
      "Completed epoch 119.\n",
      "reward_mean: 0.5507808766227442\n",
      "reward_std: 0.4217365213197292\n",
      "augmented_reward: -5.876288434472215\n",
      "completion_length_mean: 88.22378053860149\n",
      "completion_length_std: 5.74658298284402\n",
      "kld_t-1: -0.002618692269217646\n",
      "kld_0: -1.177437721596974\n",
      "entropy: 2.041483662913365\n",
      "\n",
      "Completed epoch 139.\n",
      "reward_mean: 0.6149611684514322\n",
      "reward_std: 0.4103933892600375\n",
      "augmented_reward: -5.282057169481001\n",
      "completion_length_mean: 88.19016754002783\n",
      "completion_length_std: 6.150456848479619\n",
      "kld_t-1: -0.0025250636892240126\n",
      "kld_0: -1.1066882092802672\n",
      "entropy: 1.756547413874559\n",
      "\n",
      "(Epoch: 149) Saved model to actor_149.model\n",
      "Completed epoch 159.\n",
      "reward_mean: 0.6674120263990623\n",
      "reward_std: 0.3946985140256523\n",
      "augmented_reward: -4.680949412684501\n",
      "completion_length_mean: 88.07410117115036\n",
      "completion_length_std: 6.987462622708533\n",
      "kld_t-1: -0.0008310917631729941\n",
      "kld_0: -0.960713967873929\n",
      "entropy: 1.560681784114344\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mppo_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/minRLHF/minRLHF/ppo_trainer.py:198\u001b[0m, in \u001b[0;36mPPOTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/minRLHF/ppo_trainer.py?line=194'>195</a>\u001b[0m \u001b[39m# Generate rollout_batches_per_epoch * rollout_batch_size rollouts\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/minRLHF/ppo_trainer.py?line=195'>196</a>\u001b[0m \u001b[39mfor\u001b[39;00m rollout_batch_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrollout_batches_per_epoch):\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/minRLHF/ppo_trainer.py?line=196'>197</a>\u001b[0m     \u001b[39m# print(f'Generating rollout batch {rollout_batch_idx}')\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/ubuntu/minRLHF/minRLHF/ppo_trainer.py?line=197'>198</a>\u001b[0m     rollout \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_rollout()\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/minRLHF/ppo_trainer.py?line=198'>199</a>\u001b[0m     rollout \u001b[39m=\u001b[39m gather_dict(rollout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/minRLHF/ppo_trainer.py?line=199'>200</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer\u001b[39m.\u001b[39mstore(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mrollout)\n",
      "File \u001b[0;32m~/minRLHF/minRLHF/ppo_trainer.py:171\u001b[0m, in \u001b[0;36mPPOTrainer.get_rollout\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/minRLHF/ppo_trainer.py?line=168'>169</a>\u001b[0m \u001b[39m# Rewards computed by environment on cpu\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/minRLHF/ppo_trainer.py?line=169'>170</a>\u001b[0m data \u001b[39m=\u001b[39m gather_dict(data, torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m), keys\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mcompletion_ids\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mprompt_mask\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcompletion_mask\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> <a href='file:///home/ubuntu/minRLHF/minRLHF/ppo_trainer.py?line=170'>171</a>\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39mreward\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mget_rewards(data[\u001b[39m'\u001b[39;49m\u001b[39mcompletion_ids\u001b[39;49m\u001b[39m'\u001b[39;49m], data[\u001b[39m'\u001b[39;49m\u001b[39mprompt_mask\u001b[39;49m\u001b[39m'\u001b[39;49m], data[\u001b[39m'\u001b[39;49m\u001b[39mcompletion_mask\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/minRLHF/ppo_trainer.py?line=172'>173</a>\u001b[0m \u001b[39m# Compute critic value estimates on critic device\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/minRLHF/ppo_trainer.py?line=173'>174</a>\u001b[0m data \u001b[39m=\u001b[39m gather_dict(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcritic\u001b[39m.\u001b[39mdevice, keys\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mcompletion_ids\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mprompt_mask\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcompletion_mask\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/minRLHF/minRLHF/environment.py:31\u001b[0m, in \u001b[0;36mEnvironment.get_rewards\u001b[0;34m(self, output_ids, input_mask, output_mask)\u001b[0m\n\u001b[1;32m     <a href='file:///home/ubuntu/minRLHF/minRLHF/environment.py?line=27'>28</a>\u001b[0m     texts\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mdecode(ids, skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n\u001b[1;32m     <a href='file:///home/ubuntu/minRLHF/minRLHF/environment.py?line=29'>30</a>\u001b[0m \u001b[39m# Score the completions\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/ubuntu/minRLHF/minRLHF/environment.py?line=30'>31</a>\u001b[0m scores \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscore_generation(text) \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m texts]\n\u001b[1;32m     <a href='file:///home/ubuntu/minRLHF/minRLHF/environment.py?line=32'>33</a>\u001b[0m \u001b[39m# Rewards[i, j] = \u001b[39;00m\n\u001b[1;32m     <a href='file:///home/ubuntu/minRLHF/minRLHF/environment.py?line=33'>34</a>\u001b[0m \u001b[39m#   reward score    if j is last generated token of ith example\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/ubuntu/minRLHF/minRLHF/environment.py?line=34'>35</a>\u001b[0m \u001b[39m#   0               otherwise\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/ubuntu/minRLHF/minRLHF/environment.py?line=35'>36</a>\u001b[0m idxs \u001b[39m=\u001b[39m \u001b[39m-\u001b[39moutput_mask\u001b[39m.\u001b[39mflip(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39margmax(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39m# index of last generated token # TODO: Make less cryptic\u001b[39;00m\n",
      "File \u001b[0;32m~/minRLHF/minRLHF/environment.py:31\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='file:///home/ubuntu/minRLHF/minRLHF/environment.py?line=27'>28</a>\u001b[0m     texts\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mdecode(ids, skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n\u001b[1;32m     <a href='file:///home/ubuntu/minRLHF/minRLHF/environment.py?line=29'>30</a>\u001b[0m \u001b[39m# Score the completions\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/ubuntu/minRLHF/minRLHF/environment.py?line=30'>31</a>\u001b[0m scores \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscore_generation(text) \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m texts]\n\u001b[1;32m     <a href='file:///home/ubuntu/minRLHF/minRLHF/environment.py?line=32'>33</a>\u001b[0m \u001b[39m# Rewards[i, j] = \u001b[39;00m\n\u001b[1;32m     <a href='file:///home/ubuntu/minRLHF/minRLHF/environment.py?line=33'>34</a>\u001b[0m \u001b[39m#   reward score    if j is last generated token of ith example\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/ubuntu/minRLHF/minRLHF/environment.py?line=34'>35</a>\u001b[0m \u001b[39m#   0               otherwise\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/ubuntu/minRLHF/minRLHF/environment.py?line=35'>36</a>\u001b[0m idxs \u001b[39m=\u001b[39m \u001b[39m-\u001b[39moutput_mask\u001b[39m.\u001b[39mflip(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39margmax(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39m# index of last generated token # TODO: Make less cryptic\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [1], line 26\u001b[0m, in \u001b[0;36mMyEnv.score_generation\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscore_generation\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m---> 26\u001b[0m     sentiment_scores \u001b[38;5;241m=\u001b[39m \u001b[43mreward_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     27\u001b[0m     sentiment_scores \u001b[38;5;241m=\u001b[39m {d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]: d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m sentiment_scores}\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sentiment_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjoy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/text_classification.py:140\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/text_classification.py?line=105'>106</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/text_classification.py?line=106'>107</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/text_classification.py?line=107'>108</a>\u001b[0m \u001b[39m    Classify the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/text_classification.py?line=108'>109</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/text_classification.py?line=137'>138</a>\u001b[0m \u001b[39m        If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/text_classification.py?line=138'>139</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/text_classification.py?line=139'>140</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/text_classification.py?line=140'>141</a>\u001b[0m     \u001b[39m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/text_classification.py?line=141'>142</a>\u001b[0m     _legacy \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtop_k\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m kwargs\n",
      "File \u001b[0;32m~/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/base.py:1074\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/base.py?line=1071'>1072</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/base.py?line=1072'>1073</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/base.py?line=1073'>1074</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m~/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/base.py:1081\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/base.py?line=1078'>1079</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_single\u001b[39m(\u001b[39mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/base.py?line=1079'>1080</a>\u001b[0m     model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/base.py?line=1080'>1081</a>\u001b[0m     model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/base.py?line=1081'>1082</a>\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostprocess(model_outputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpostprocess_params)\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/base.py?line=1082'>1083</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/base.py:990\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/base.py?line=987'>988</a>\u001b[0m     \u001b[39mwith\u001b[39;00m inference_context():\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/base.py?line=988'>989</a>\u001b[0m         model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/base.py?line=989'>990</a>\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/base.py?line=990'>991</a>\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/base.py?line=991'>992</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/text_classification.py:167\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/text_classification.py?line=165'>166</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward\u001b[39m(\u001b[39mself\u001b[39m, model_inputs):\n\u001b[0;32m--> <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/pipelines/text_classification.py?line=166'>167</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs)\n",
      "File \u001b[0;32m~/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:747\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=738'>739</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=739'>740</a>\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=740'>741</a>\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=741'>742</a>\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=742'>743</a>\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=743'>744</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=744'>745</a>\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m--> <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=746'>747</a>\u001b[0m distilbert_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdistilbert(\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=747'>748</a>\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=748'>749</a>\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=749'>750</a>\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=750'>751</a>\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=751'>752</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=752'>753</a>\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=753'>754</a>\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=754'>755</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=755'>756</a>\u001b[0m hidden_state \u001b[39m=\u001b[39m distilbert_output[\u001b[39m0\u001b[39m]  \u001b[39m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=756'>757</a>\u001b[0m pooled_output \u001b[39m=\u001b[39m hidden_state[:, \u001b[39m0\u001b[39m]  \u001b[39m# (bs, dim)\u001b[39;00m\n",
      "File \u001b[0;32m~/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:567\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=564'>565</a>\u001b[0m \u001b[39mif\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=565'>566</a>\u001b[0m     inputs_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(input_ids)  \u001b[39m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=566'>567</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=567'>568</a>\u001b[0m     x\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=568'>569</a>\u001b[0m     attn_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=569'>570</a>\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=570'>571</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=571'>572</a>\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=572'>573</a>\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=573'>574</a>\u001b[0m )\n",
      "File \u001b[0;32m~/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:345\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=341'>342</a>\u001b[0m \u001b[39mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=342'>343</a>\u001b[0m     all_hidden_states \u001b[39m=\u001b[39m all_hidden_states \u001b[39m+\u001b[39m (hidden_state,)\n\u001b[0;32m--> <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=344'>345</a>\u001b[0m layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=345'>346</a>\u001b[0m     x\u001b[39m=\u001b[39;49mhidden_state, attn_mask\u001b[39m=\u001b[39;49mattn_mask, head_mask\u001b[39m=\u001b[39;49mhead_mask[i], output_attentions\u001b[39m=\u001b[39;49moutput_attentions\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=346'>347</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=347'>348</a>\u001b[0m hidden_state \u001b[39m=\u001b[39m layer_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=349'>350</a>\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:283\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=272'>273</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=273'>274</a>\u001b[0m \u001b[39mParameters:\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=274'>275</a>\u001b[0m \u001b[39m    x: torch.tensor(bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=279'>280</a>\u001b[0m \u001b[39m    torch.tensor(bs, seq_length, dim) The output of the transformer block contextualization.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=280'>281</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=281'>282</a>\u001b[0m \u001b[39m# Self-Attention\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=282'>283</a>\u001b[0m sa_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=283'>284</a>\u001b[0m     query\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=284'>285</a>\u001b[0m     key\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=285'>286</a>\u001b[0m     value\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=286'>287</a>\u001b[0m     mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=287'>288</a>\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=288'>289</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=289'>290</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=290'>291</a>\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=291'>292</a>\u001b[0m     sa_output, sa_weights \u001b[39m=\u001b[39m sa_output  \u001b[39m# (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\u001b[39;00m\n",
      "File \u001b[0;32m~/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:207\u001b[0m, in \u001b[0;36mMultiHeadSelfAttention.forward\u001b[0;34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=204'>205</a>\u001b[0m q \u001b[39m=\u001b[39m shape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_lin(query))  \u001b[39m# (bs, n_heads, q_length, dim_per_head)\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=205'>206</a>\u001b[0m k \u001b[39m=\u001b[39m shape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_lin(key))  \u001b[39m# (bs, n_heads, k_length, dim_per_head)\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=206'>207</a>\u001b[0m v \u001b[39m=\u001b[39m shape(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mv_lin(value))  \u001b[39m# (bs, n_heads, k_length, dim_per_head)\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=208'>209</a>\u001b[0m q \u001b[39m=\u001b[39m q \u001b[39m/\u001b[39m math\u001b[39m.\u001b[39msqrt(dim_per_head)  \u001b[39m# (bs, n_heads, q_length, dim_per_head)\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py?line=209'>210</a>\u001b[0m scores \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmatmul(q, k\u001b[39m.\u001b[39mtranspose(\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m))  \u001b[39m# (bs, n_heads, q_length, k_length)\u001b[39;00m\n",
      "File \u001b[0;32m~/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/linear.py?line=101'>102</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///home/ubuntu/minRLHF/.venv/lib/python3.8/site-packages/torch/nn/modules/linear.py?line=102'>103</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ppo_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'mean reward')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xs = list(range(len(ppo_trainer.collected_rewards)))\n",
    "ys = ppo_trainer.collected_rewards\n",
    "\n",
    "plt.scatter(xs, ys)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('mean reward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can load a saved checkpoint if you wish\n",
    "# tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "model = AutoModelForCausalLM.from_pretrained('actor_99.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yesterday, I got the whole news that Tom Curry, who was the new coach of the Warriors, was going to be taking a new team to L.A., but it seems like they're looking up at the Lakers.\n",
      "\n",
      "I'm kind of like, \"Why would they bring this back to that point when this team was really good that year when they really played really good football?\"\n",
      "\n",
      "They'd been in a different league and that team was so good for so long. Now,\n"
     ]
    }
   ],
   "source": [
    "# Try out some generations\n",
    "\n",
    "inputs = tokenizer('Yesterday, I', return_tensors='pt')\n",
    "outputs = model.generate(inputs.input_ids.to(model.device), do_sample=True, max_length=100)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3f08a5f13ca9247f60687871aeb0db0c250749e5b174701901907dc6c613fa60"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
